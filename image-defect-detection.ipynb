{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloth defect detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "print(\"GPU is\", \"available\" if torch.cuda.is_available() else \"NOT AVAILABLE\")\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import images dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = (480, 640)\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "#dataset_description_path = \"C:\\Users\\Drake Li\\Desktop\\cwd\\ds-stuff\\data\\list.txt\"\n",
    "dataset_path = \"./data/cloth-defect-detect\"\n",
    "dataset_path_eval = \"./data/eval-imgs\"\n",
    "\n",
    "anno_path=\"./data/cloth-defect-detect/anno_train.json\"\n",
    "labels_path = \"./cloth-defect-detect-classes.json\"\n",
    "model_path = \"./cloth-defect-detect.pth\"    #save to here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/cloth-defect-detect\\anno_train.json\n",
      "63\n",
      "0907A1_081eed8e1d64b06a1201909071528592.jpg\n",
      "./data/cloth-defect-detect\\defect\\0907A1_081eed8e1d64b06a1201909071528592\\0907A1_081eed8e1d64b06a1201909071528592.jpg\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "dataset=[]\n",
    "\n",
    "classes = {}\n",
    "labelcounter=0\n",
    "annolabels=None\n",
    "\n",
    "img_fn_dict={}\n",
    "img_fn_dict_eval={}\n",
    "def load_fndict(img_fn_dict_out,dataset_folder):\n",
    "    for i,fn in enumerate(os.listdir(dataset_folder)):\n",
    "        datapath=os.path.join(dataset_folder,fn)\n",
    "        if(os.path.isdir(datapath)==False):\n",
    "            print(datapath)\n",
    "            continue\n",
    "        #either defect or normal\n",
    "        if(fn==\"defect\"):\n",
    "\n",
    "            #load defect\n",
    "            for j,fn_defect in enumerate(os.listdir(datapath)):\n",
    "                #print(fn_defect)\n",
    "                img_fullpath=os.path.join(datapath,fn_defect,fn_defect+\".jpg\")\n",
    "                img_fn_dict_out[fn_defect+\".jpg\"]=img_fullpath\n",
    "    return\n",
    "load_fndict(img_fn_dict,dataset_path)\n",
    "load_fndict(img_fn_dict_eval,dataset_path_eval)\n",
    "\n",
    "print(len(img_fn_dict_eval))\n",
    "for item in img_fn_dict:\n",
    "    print(item)\n",
    "    print(img_fn_dict[item])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/cloth-defect-detect\n",
      "files:1984\n",
      "anno len:16457\n",
      "{'缝头': 0, '缝头印': 1, '沾污': 2, '漏印': 3, '虫粘': 4, '花毛': 5, '水印': 6, '色差': 7, '褶子': 8, '破洞': 9, '织疵': 10, '蜡斑': 11, '错花': 12, '其他': 13, '网折': 14}\n",
      "{0: '缝头', 1: '缝头印', 2: '沾污', 3: '漏印', 4: '虫粘', 5: '花毛', 6: '水印', 7: '色差', 8: '褶子', 9: '破洞', 10: '织疵', 11: '蜡斑', 12: '错花', 13: '其他', 14: '网折'}\n",
      "[{'x1': 1, 'x2': 4087, 'y1': 1073, 'y2': 1198, 'class': '缝头'}]\n",
      "[{'x1': 4, 'x2': 4085, 'y1': 760, 'y2': 881, 'class': '缝头印'}]\n",
      "[{'x1': 2111, 'x2': 2182, 'y1': 1561, 'y2': 1596, 'class': '沾污'}]\n",
      "[{'x1': 0, 'x2': 390, 'y1': 0, 'y2': 1691, 'class': '漏印'}]\n",
      "[{'x1': 0, 'x2': 4096, 'y1': 1116, 'y2': 1205, 'class': '缝头'}]\n",
      "files:1984\n",
      "anno len:16457\n",
      "{'缝头': 0, '缝头印': 1, '沾污': 2, '漏印': 3, '虫粘': 4, '花毛': 5, '水印': 6, '色差': 7, '褶子': 8, '破洞': 9, '织疵': 10, '蜡斑': 11, '错花': 12, '其他': 13, '网折': 14}\n",
      "{0: '缝头', 1: '缝头印', 2: '沾污', 3: '漏印', 4: '虫粘', 5: '花毛', 6: '水印', 7: '色差', 8: '褶子', 9: '破洞', 10: '织疵', 11: '蜡斑', 12: '错花', 13: '其他', 14: '网折'}\n",
      "[{'x1': 1, 'x2': 4087, 'y1': 1073, 'y2': 1198, 'class': '缝头'}]\n",
      "[{'x1': 4, 'x2': 4085, 'y1': 760, 'y2': 881, 'class': '缝头印'}]\n",
      "[{'x1': 2111, 'x2': 2182, 'y1': 1561, 'y2': 1596, 'class': '沾污'}]\n",
      "[{'x1': 0, 'x2': 390, 'y1': 0, 'y2': 1691, 'class': '漏印'}]\n",
      "[{'x1': 0, 'x2': 4096, 'y1': 1116, 'y2': 1205, 'class': '缝头'}]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import skimage.color\n",
    "import skimage\n",
    "from retinanet.dataloader import fileDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, Normalizer\n",
    "from retinanet import csv_eval\n",
    "\n",
    "print(dataset_path)\n",
    "#train\n",
    "dataset_train =fileDataset(dataset_path,anno_path,img_fn_dict,IMG_SIZE=IMG_SIZE,transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n",
    "sampler = AspectRatioBasedSampler(dataset_train, batch_size=16, drop_last=False)\n",
    "# dataloader_train = DataLoader(dataset_train, num_workers=3, collate_fn=collater, batch_sampler=sampler)\n",
    "dataloader_train = DataLoader(dataset_train,collate_fn=collater,batch_sampler=sampler)\n",
    "\n",
    "#validation\n",
    "dataset_val = fileDataset(dataset_path_eval,anno_path,img_fn_dict,IMG_SIZE=IMG_SIZE,\n",
    "                                     transform=transforms.Compose([Normalizer(), Resizer()]))\n",
    "sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=1, drop_last=False)\n",
    "dataloader_val = DataLoader(dataset_val, num_workers=3, collate_fn=collater, batch_sampler=sampler_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes dumped to ./cloth-defect-detect-classes.json.\n"
     ]
    }
   ],
   "source": [
    "#dump classes to file\n",
    "with open(labels_path,\"w\") as fp1:\n",
    "    json.dump(dataset_train.classes,fp1)\n",
    "print(\"classes dumped to {}.\".format(labels_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretrained model\n",
    "from torchsummary import summary\n",
    "\n",
    "from retinanet import model\n",
    "retinanet = model.resnet34(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "retinanet = retinanet.cuda()\n",
    "retinanet = torch.nn.DataParallel(retinanet).cuda()\n",
    "\n",
    "#print(retinanet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images: 1984\n",
      "Epoch: 0 | Iteration: 0 | Classification loss: 0.45720 | Regression loss: 0.06256 | Running loss: 0.51976\n",
      "Epoch: 0 | Iteration: 1 | Classification loss: 0.23140 | Regression loss: 0.14358 | Running loss: 0.44737\n",
      "Epoch: 0 | Iteration: 2 | Classification loss: 0.49791 | Regression loss: 0.33930 | Running loss: 0.57732\n",
      "Epoch: 0 | Iteration: 3 | Classification loss: 0.62502 | Regression loss: 0.66051 | Running loss: 0.75437\n",
      "Epoch: 0 | Iteration: 4 | Classification loss: 0.29800 | Regression loss: 0.17284 | Running loss: 0.69766\n",
      "Epoch: 0 | Iteration: 5 | Classification loss: 0.00123 | Regression loss: 0.00000 | Running loss: 0.58159\n",
      "Epoch: 0 | Iteration: 6 | Classification loss: 0.28831 | Regression loss: 0.26493 | Running loss: 0.57754\n",
      "Epoch: 0 | Iteration: 7 | Classification loss: 1.20640 | Regression loss: 0.99044 | Running loss: 0.77995\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import collections\n",
    "\n",
    "retinanet.training = True\n",
    "\n",
    "optimizer = optim.Adam(retinanet.parameters(), lr=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "loss_hist = collections.deque(maxlen=500)\n",
    "retinanet.train()\n",
    "retinanet.module.freeze_bn()\n",
    "print('Num training images: {}'.format(len(dataset_train)))\n",
    "for epoch_num in range(NUM_EPOCHS):\n",
    "    retinanet.train()\n",
    "    retinanet.module.freeze_bn()\n",
    "    epoch_loss = []\n",
    "    for iter_num, data in enumerate(dataloader_train):\n",
    "        optimizer.zero_grad()\n",
    "        images=data['img'].cuda().float()\n",
    "        annot=data['annot']\n",
    "        #print(images.shape)\n",
    "        #b = images.permute(0,3,1,2)#rearrange shape\n",
    "        #b = images.permute(0,3,1,2)\n",
    "        #print(b.shape)\n",
    "        #print(annot.shape)\n",
    "        classification_loss, regression_loss = retinanet([images, annot])\n",
    "        \n",
    "        classification_loss = classification_loss.mean()\n",
    "        #print(classification_loss)\n",
    "        regression_loss = regression_loss.mean()\n",
    "        loss = classification_loss + regression_loss\n",
    "        if bool(loss == 0):\n",
    "            print(\"loss == 0\")\n",
    "            continue\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        loss_hist.append(float(loss))\n",
    "        epoch_loss.append(float(loss))\n",
    "        print(\n",
    "                    'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n",
    "                        epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(loss_hist)))\n",
    "        del classification_loss\n",
    "        del regression_loss\n",
    "        del images\n",
    "        \n",
    "    print('Evaluating dataset')\n",
    "    mAP = csv_eval.evaluate(dataset_val, retinanet)\n",
    "    scheduler.step(np.mean(epoch_loss))\n",
    "    torch.save(retinanet.module, '{}_retinanet_{}.pt'.format(parser.dataset, epoch_num))\n",
    "retinanet.eval()\n",
    "torch.save(retinanet, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try evaluate on train dataset\n",
    "print('Evaluating dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
