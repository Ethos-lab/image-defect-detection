{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import images dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = (480, 640)\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "#dataset_description_path = \"C:\\Users\\Drake Li\\Desktop\\cwd\\ds-stuff\\data\\list.txt\"\n",
    "dataset_path = \"./data/cloth-defect-detect\"\n",
    "anno_path=\"./data/cloth-defect-detect/anno_train.json\"\n",
    "labels_path = \"./cloth-defect-detect-classes.json\"\n",
    "model_path = \"./cloth-defect-detect.pth\"    #save to here\n",
    "\n",
    "image_path=\"./data/eval-imgs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'缝头': 0, '缝头印': 1, '沾污': 2, '漏印': 3, '虫粘': 4, '花毛': 5, '水印': 6, '色差': 7, '褶子': 8, '破洞': 9, '织疵': 10, '蜡斑': 11, '错花': 12, '其他': 13, '网折': 14}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def load_classes(class_filepath):\n",
    "    result = {}\n",
    "    with open(class_filepath,\"r\") as fp1:\n",
    "        result = json.load(fp1)\n",
    "    return result\n",
    "# Draws a caption above the box in an image\n",
    "def draw_caption(image, box, caption):\n",
    "    b = np.array(box).astype(int)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1)\n",
    "\n",
    "print(load_classes(labels_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def detect_image(image_path, model_path, class_path):\n",
    "    \n",
    "    classes = load_classes(class_path)\n",
    "\n",
    "    labels = {}\n",
    "    for key, value in classes.items():\n",
    "        labels[value] = key\n",
    "\n",
    "    model = torch.load(model_path)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    model.training = False\n",
    "    model.eval()\n",
    "\n",
    "    for img_name in os.listdir(image_path):\n",
    "\n",
    "        image = cv2.imread(os.path.join(image_path, img_name))\n",
    "        if image is None:\n",
    "            continue\n",
    "        image_orig = image.copy()\n",
    "\n",
    "        rows, cols, cns = image.shape\n",
    "\n",
    "        smallest_side = min(rows, cols)\n",
    "\n",
    "        # rescale the image so the smallest side is min_side\n",
    "        min_side = IMG_SIZE[0]\n",
    "        max_side = IMG_SIZE[1]\n",
    "        scale = min_side / smallest_side\n",
    "\n",
    "        # check if the largest side is now greater than max_side, which can happen\n",
    "        # when images have a large aspect ratio\n",
    "        largest_side = max(rows, cols)\n",
    "\n",
    "        if largest_side * scale > max_side:\n",
    "            scale = max_side / largest_side\n",
    "\n",
    "        # resize the image with the computed scale\n",
    "        image = cv2.resize(image, (int(round(cols * scale)), int(round((rows * scale)))))\n",
    "        rows, cols, cns = image.shape\n",
    "\n",
    "        pad_w = 32 - rows % 32\n",
    "        pad_h = 32 - cols % 32\n",
    "\n",
    "        new_image = np.zeros((rows + pad_w, cols + pad_h, cns)).astype(np.float32)\n",
    "        new_image[:rows, :cols, :] = image.astype(np.float32)\n",
    "        image = new_image.astype(np.float32)\n",
    "        image /= 255\n",
    "        image -= [0.485, 0.456, 0.406]\n",
    "        image /= [0.229, 0.224, 0.225]\n",
    "        image = np.expand_dims(image, 0)\n",
    "        image = np.transpose(image, (0, 3, 1, 2))\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            image = torch.from_numpy(image)\n",
    "            if torch.cuda.is_available():\n",
    "                image = image.cuda()\n",
    "\n",
    "            st = time.time()\n",
    "            print(image.shape, image_orig.shape, scale)\n",
    "            scores, classification, transformed_anchors = model(image.cuda().float())\n",
    "            print('Elapsed time: {}'.format(time.time() - st))\n",
    "            print(scores)\n",
    "            print(classification)\n",
    "            idxs = np.where(scores.cpu() > 0.5)\n",
    "            #print(idxs)\n",
    "            for j in range(idxs[0].shape[0]):\n",
    "                bbox = transformed_anchors[idxs[0][j], :]\n",
    "\n",
    "                x1 = int(bbox[0] / scale)\n",
    "                y1 = int(bbox[1] / scale)\n",
    "                x2 = int(bbox[2] / scale)\n",
    "                y2 = int(bbox[3] / scale)\n",
    "                label_name = labels[int(classification[idxs[0][j]])]\n",
    "                print(bbox, classification.shape)\n",
    "                score = scores[j]\n",
    "                caption = '{} {:.3f}'.format(label_name, score)\n",
    "                # draw_caption(img, (x1, y1, x2, y2), label_name)\n",
    "                draw_caption(image_orig, (x1, y1, x2, y2), caption)\n",
    "                cv2.rectangle(image_orig, (x1, y1), (x2, y2), color=(0, 0, 255), thickness=2)\n",
    "\n",
    "            cv2.imshow('detections', image_orig)\n",
    "            cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 288, 672]) (450, 1024, 3) 0.625\n",
      "Elapsed time: 0.2672431468963623\n",
      "tensor([], device='cuda:0')\n",
      "tensor([], device='cuda:0', dtype=torch.int64)\n",
      "torch.Size([1, 3, 288, 672]) (452, 1024, 3) 0.625\n",
      "Elapsed time: 0.24733519554138184\n",
      "tensor([], device='cuda:0')\n",
      "tensor([], device='cuda:0', dtype=torch.int64)\n",
      "torch.Size([1, 3, 288, 672]) (530, 1280, 3) 0.5\n",
      "Elapsed time: 0.24422216415405273\n",
      "tensor([], device='cuda:0')\n",
      "tensor([], device='cuda:0', dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "detect_image(image_path, model_path, labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
